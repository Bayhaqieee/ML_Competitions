{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1oV2A2mi6TWoYsuzup3a2LqP8WJVijwiU",
      "authorship_tag": "ABX9TyMZBXp11jfGWeFdLhQsX8bo"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sQroeAEb0LG",
        "outputId": "b78d0c04-0712-47b7-96c5-1c4d4aa76960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.13.1)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.2.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.37)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.2.0-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.4/383.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.9 alembic-1.14.1 colorlog-6.9.0 optuna-4.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install scikit-learn\n",
        "!pip install xgboost\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "import xgboost as xgb\n",
        "import optuna"
      ],
      "metadata": {
        "id": "RcIrQ80Lag-D"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "k3xYcitIbnxk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/CollabData/kaggle_API/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "mnkqlepJbrsS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "eSpCymNdbrgd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions download home-data-for-ml-course"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szU1ARtBbyPI",
        "outputId": "40dacbff-b5de-4aa9-9361-cc99abfdfe2e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading home-data-for-ml-course.zip to /content\n",
            "\r  0% 0.00/386k [00:00<?, ?B/s]\n",
            "\r100% 386k/386k [00:00<00:00, 79.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip home-data-for-ml-course.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHYiha3IcczE",
        "outputId": "4c8c3162-0e48-4cf8-af8f-26085f2bc618"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  home-data-for-ml-course.zip\n",
            "  inflating: data_description.txt    \n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: sample_submission.csv.gz  \n",
            "  inflating: test.csv                \n",
            "  inflating: test.csv.gz             \n",
            "  inflating: train.csv               \n",
            "  inflating: train.csv.gz            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# Separate features and target variable\n",
        "X = train_df.drop('SalePrice', axis=1)\n",
        "y = train_df['SalePrice']\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Preprocessing: Handling categorical and numerical features\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "numerical_features = X.select_dtypes(exclude=['object']).columns\n",
        "\n",
        "# One-hot encoding for categorical features\n",
        "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "X_train_encoded = pd.DataFrame(encoder.fit_transform(X_train[categorical_features]))\n",
        "X_val_encoded = pd.DataFrame(encoder.transform(X_val[categorical_features]))\n",
        "X_test_encoded = pd.DataFrame(encoder.transform(test_df[categorical_features]))\n",
        "\n",
        "# Scaling numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train[numerical_features]))\n",
        "X_val_scaled = pd.DataFrame(scaler.transform(X_val[numerical_features]))\n",
        "X_test_scaled = pd.DataFrame(scaler.transform(test_df[numerical_features]))\n",
        "\n",
        "# Concatenate encoded and scaled features\n",
        "X_train_processed = pd.concat([X_train_scaled, X_train_encoded], axis=1)\n",
        "X_val_processed = pd.concat([X_val_scaled, X_val_encoded], axis=1)\n",
        "X_test_processed = pd.concat([X_test_scaled, X_test_encoded], axis=1)"
      ],
      "metadata": {
        "id": "_t8VdP0Fbh-O"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        'objective': 'reg:squarederror',\n",
        "        'eval_metric': 'rmse',\n",
        "        'booster': 'gbtree',\n",
        "        'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log=True),\n",
        "        'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log=True),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 1.0),\n",
        "        'subsample': trial.suggest_float('subsample', 0.4, 1.0),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 3e-3, 0.1, log=True),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'gamma': trial.suggest_float('gamma', 0, 1),\n",
        "    }\n",
        "\n",
        "    model = xgb.XGBRegressor(**params)\n",
        "    # Use fit() with eval_set and early_stopping_rounds as separate parameters for the xgb.train function instead of xgb.XGBRegressor\n",
        "    model.fit(X_train_processed, y_train,\n",
        "              eval_set=[(X_val_processed, y_val)],\n",
        "              early_stopping_rounds=10, # Pass early_stopping_rounds as a separate argument\n",
        "              verbose=False)\n",
        "    return model.best_score # Assuming 'best_score' is an attribute of your model"
      ],
      "metadata": {
        "id": "yMeIKtCDcuBj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = xgb.XGBRegressor(**best_params)\n",
        "final_model.fit(X_train_processed, y_train)\n",
        "\n",
        "predictions = final_model.predict(X_test_processed)"
      ],
      "metadata": {
        "id": "3wJDNMKRdBnv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}