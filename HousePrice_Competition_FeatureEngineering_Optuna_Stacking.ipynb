{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sQroeAEb0LG",
        "outputId": "dee9b75a-4c66-48e3-adc4-e25c308cb08f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.13.1)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.38)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.9 alembic-1.14.1 colorlog-6.9.0 optuna-4.2.1\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.13.1)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install scikit-learn\n",
        "!pip install xgboost\n",
        "!pip install optuna\n",
        "!pip install lightgbm\n",
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RcIrQ80Lag-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30bb2724-5e12-4030-f59c-448f1f6e70ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np # Import numpy for log1p and expm1\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "import xgboost as xgb\n",
        "import optuna\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.linear_model import LinearRegression, ElasticNet, Lasso\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.compose import TransformedTargetRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "k3xYcitIbnxk"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mnkqlepJbrsS"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/CollabData/kaggle_API/kaggle.json ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eSpCymNdbrgd"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szU1ARtBbyPI",
        "outputId": "13cc23f8-26bd-4aa9-aada-ae0dc75f6daa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading home-data-for-ml-course.zip to /content\n",
            "\r  0% 0.00/386k [00:00<?, ?B/s]\n",
            "\r100% 386k/386k [00:00<00:00, 91.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "! kaggle competitions download home-data-for-ml-course"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHYiha3IcczE",
        "outputId": "896b1947-48d8-4a7f-845b-0f200142019a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  home-data-for-ml-course.zip\n",
            "  inflating: data_description.txt    \n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: sample_submission.csv.gz  \n",
            "  inflating: test.csv                \n",
            "  inflating: test.csv.gz             \n",
            "  inflating: train.csv               \n",
            "  inflating: train.csv.gz            \n"
          ]
        }
      ],
      "source": [
        "! unzip home-data-for-ml-course.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_t8VdP0Fbh-O"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# Separate features and target variable\n",
        "X = train_df.drop('SalePrice', axis=1)\n",
        "y = train_df['SalePrice']\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Preprocessing: Handling categorical and numerical features\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "numerical_features = X.select_dtypes(exclude=['object']).columns\n",
        "\n",
        "# Impute missing values in numerical features using the mean\n",
        "imputer = SimpleImputer(strategy='mean') # Create an imputer instance\n",
        "X_train[numerical_features] = imputer.fit_transform(X_train[numerical_features]) # Fit and transform on training data\n",
        "X_val[numerical_features] = imputer.transform(X_val[numerical_features]) # Transform validation data\n",
        "test_df[numerical_features] = imputer.transform(test_df[numerical_features]) # Transform test data\n",
        "\n",
        "\n",
        "# Initialize KBinsDiscretizer with 'uniform' strategy for tree-like binning\n",
        "kbd = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\n",
        "\n",
        "# Apply KBinsDiscretizer to numerical features\n",
        "X_train_kbd = kbd.fit_transform(X_train[numerical_features])\n",
        "X_val_kbd = kbd.transform(X_val[numerical_features])\n",
        "X_test_kbd = kbd.transform(test_df[numerical_features])\n",
        "\n",
        "# Convert the output back to DataFrames\n",
        "X_train_kbd = pd.DataFrame(X_train_kbd, columns=numerical_features, index=X_train.index)\n",
        "X_val_kbd = pd.DataFrame(X_val_kbd, columns=numerical_features, index=X_val.index)\n",
        "X_test_kbd = pd.DataFrame(X_test_kbd, columns=numerical_features, index=test_df.index)\n",
        "\n",
        "# One-hot encode categorical features\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore') # Create an encoder instance\n",
        "X_train_encoded = encoder.fit_transform(X_train[categorical_features]) # Fit and transform on training data\n",
        "X_val_encoded = encoder.transform(X_val[categorical_features]) # Transform validation data\n",
        "X_test_encoded = encoder.transform(test_df[categorical_features]) # Transform test data\n",
        "\n",
        "# Convert encoded features to DataFrames with appropriate column names\n",
        "X_train_encoded = pd.DataFrame(X_train_encoded, columns=encoder.get_feature_names_out(categorical_features), index=X_train.index)\n",
        "X_val_encoded = pd.DataFrame(X_val_encoded, columns=encoder.get_feature_names_out(categorical_features), index=X_val.index)\n",
        "X_test_encoded = pd.DataFrame(X_test_encoded, columns=encoder.get_feature_names_out(categorical_features), index=test_df.index)\n",
        "\n",
        "\n",
        "# Concatenate the preprocessed numerical features with encoded categorical features\n",
        "X_train_processed = pd.concat([X_train_kbd, X_train_encoded], axis=1)\n",
        "X_val_processed = pd.concat([X_val_kbd, X_val_encoded], axis=1)\n",
        "X_test_processed = pd.concat([X_test_kbd, X_test_encoded], axis=1)\n",
        "\n",
        "# Define tree_preprocessor and linear_preprocessor\n",
        "tree_preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),\n",
        "    ])\n",
        "\n",
        "linear_preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yMeIKtCDcuBj"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        'objective': 'reg:squarederror',\n",
        "        'eval_metric': 'rmse',\n",
        "        'booster': trial.suggest_categorical('booster', ['gbtree', 'dart']),\n",
        "        'lambda': trial.suggest_float('lambda', 1e-3, 10.0, log=True),\n",
        "        'alpha': trial.suggest_float('alpha', 1e-3, 10.0, log=True),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 0.8),\n",
        "        'subsample': trial.suggest_float('subsample', 0.4, 0.8),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 0.3, log=True),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 20),\n",
        "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
        "        'grow_policy': trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide']),\n",
        "        'early_stopping_rounds': 10\n",
        "    }\n",
        "\n",
        "    model = xgb.XGBRegressor(**params)\n",
        "    model.fit(X_train_processed, y_train,\n",
        "              eval_set=[(X_val_processed, y_val)],\n",
        "              verbose=False)\n",
        "\n",
        "    return model.best_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZkLXPZ0eUN2",
        "outputId": "f37155a3-bdd3-4ec3-acac-8b1932c53dc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-16 14:25:57,753] A new study created in memory with name: no-name-882a32e0-1e28-4805-aa26-4f9c2e229423\n",
            "[I 2025-02-16 14:26:08,186] Trial 0 finished with value: 50163.445463203374 and parameters: {'booster': 'gbtree', 'lambda': 0.011054261860797165, 'alpha': 1.5382520714105559, 'colsample_bytree': 0.3791888751455815, 'subsample': 0.6664879218564019, 'learning_rate': 0.0029738388846529103, 'n_estimators': 344, 'max_depth': 4, 'min_child_weight': 1, 'gamma': 0.6127603945410842, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 50163.445463203374.\n",
            "[I 2025-02-16 14:43:39,209] Trial 1 finished with value: 68721.21571523014 and parameters: {'booster': 'dart', 'lambda': 0.11475870743850085, 'alpha': 0.08011365116935851, 'colsample_bytree': 0.5011647184974649, 'subsample': 0.500141519720536, 'learning_rate': 0.0007440534847432022, 'n_estimators': 596, 'max_depth': 3, 'min_child_weight': 9, 'gamma': 0.5355055563922101, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 50163.445463203374.\n",
            "[I 2025-02-16 14:43:44,573] Trial 2 finished with value: 77841.98010846588 and parameters: {'booster': 'gbtree', 'lambda': 6.0531225138520135, 'alpha': 0.14309182121930952, 'colsample_bytree': 0.7512172252479529, 'subsample': 0.5478173195853996, 'learning_rate': 0.00024583473990710147, 'n_estimators': 875, 'max_depth': 7, 'min_child_weight': 14, 'gamma': 3.9806150736868986, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 50163.445463203374.\n",
            "[I 2025-02-16 14:43:47,756] Trial 3 finished with value: 44479.403980937655 and parameters: {'booster': 'gbtree', 'lambda': 0.07400627340985191, 'alpha': 0.48350063395765697, 'colsample_bytree': 0.6865454699040209, 'subsample': 0.42829620121668205, 'learning_rate': 0.0015284499675922772, 'n_estimators': 993, 'max_depth': 4, 'min_child_weight': 12, 'gamma': 2.3317278690176044, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 44479.403980937655.\n",
            "[I 2025-02-16 14:43:50,435] Trial 4 finished with value: 73486.98439570193 and parameters: {'booster': 'gbtree', 'lambda': 0.014229771301419893, 'alpha': 0.46605665539433205, 'colsample_bytree': 0.5572618172679975, 'subsample': 0.48512385399953345, 'learning_rate': 0.00035268024460694886, 'n_estimators': 892, 'max_depth': 3, 'min_child_weight': 17, 'gamma': 4.455982281864755, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 44479.403980937655.\n",
            "[I 2025-02-16 14:48:21,840] Trial 5 finished with value: 73668.34745848218 and parameters: {'booster': 'dart', 'lambda': 1.9480258361059037, 'alpha': 0.17169169905106438, 'colsample_bytree': 0.4786968113231653, 'subsample': 0.7787863095419397, 'learning_rate': 0.000966070708201981, 'n_estimators': 304, 'max_depth': 5, 'min_child_weight': 13, 'gamma': 1.118498579425219, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 44479.403980937655.\n",
            "[I 2025-02-16 14:59:57,847] Trial 6 finished with value: 40645.56907976182 and parameters: {'booster': 'dart', 'lambda': 0.01703981829666931, 'alpha': 8.170228270460473, 'colsample_bytree': 0.5138283928491769, 'subsample': 0.5534554667527353, 'learning_rate': 0.004008805706158878, 'n_estimators': 489, 'max_depth': 8, 'min_child_weight': 20, 'gamma': 1.4648673061852384, 'grow_policy': 'depthwise'}. Best is trial 6 with value: 40645.56907976182.\n",
            "[I 2025-02-16 15:00:53,176] Trial 7 finished with value: 27833.452553678064 and parameters: {'booster': 'dart', 'lambda': 0.4159644359753586, 'alpha': 0.06821005748264877, 'colsample_bytree': 0.3153176939624801, 'subsample': 0.6704750917462075, 'learning_rate': 0.11574914023470302, 'n_estimators': 838, 'max_depth': 3, 'min_child_weight': 5, 'gamma': 2.498048010572094, 'grow_policy': 'lossguide'}. Best is trial 7 with value: 27833.452553678064.\n",
            "[I 2025-02-16 15:08:49,310] Trial 8 finished with value: 38354.5877808823 and parameters: {'booster': 'dart', 'lambda': 0.005842537391643145, 'alpha': 0.4866286389142255, 'colsample_bytree': 0.5720536406129768, 'subsample': 0.54688192791323, 'learning_rate': 0.005297367474101504, 'n_estimators': 405, 'max_depth': 3, 'min_child_weight': 5, 'gamma': 0.9337249483684062, 'grow_policy': 'depthwise'}. Best is trial 7 with value: 27833.452553678064.\n",
            "[I 2025-02-16 15:08:50,127] Trial 9 finished with value: 81272.36979033457 and parameters: {'booster': 'gbtree', 'lambda': 7.310913229527012, 'alpha': 0.04840210186401532, 'colsample_bytree': 0.4725866076662487, 'subsample': 0.42890569737364, 'learning_rate': 0.0006400184621512718, 'n_estimators': 241, 'max_depth': 3, 'min_child_weight': 9, 'gamma': 4.61661240801059, 'grow_policy': 'lossguide'}. Best is trial 7 with value: 27833.452553678064.\n",
            "[I 2025-02-16 15:09:00,255] Trial 10 finished with value: 30453.23346251379 and parameters: {'booster': 'dart', 'lambda': 0.39055780812140645, 'alpha': 0.0032249742405322476, 'colsample_bytree': 0.30658102161817996, 'subsample': 0.6715214898811467, 'learning_rate': 0.17840185488315308, 'n_estimators': 712, 'max_depth': 6, 'min_child_weight': 4, 'gamma': 3.0969441551454775, 'grow_policy': 'lossguide'}. Best is trial 7 with value: 27833.452553678064.\n",
            "[I 2025-02-16 15:09:10,527] Trial 11 finished with value: 31049.207973378747 and parameters: {'booster': 'dart', 'lambda': 0.5998103898858581, 'alpha': 0.001251291766283742, 'colsample_bytree': 0.3064155608889575, 'subsample': 0.6677332544111347, 'learning_rate': 0.22750162111627864, 'n_estimators': 684, 'max_depth': 6, 'min_child_weight': 4, 'gamma': 2.8980646728556643, 'grow_policy': 'lossguide'}. Best is trial 7 with value: 27833.452553678064.\n",
            "[I 2025-02-16 15:09:13,410] Trial 12 finished with value: 32166.156864752757 and parameters: {'booster': 'dart', 'lambda': 0.3681955304929585, 'alpha': 0.005991149857773191, 'colsample_bytree': 0.3012002677959312, 'subsample': 0.6826067757446225, 'learning_rate': 0.18793894022927493, 'n_estimators': 752, 'max_depth': 6, 'min_child_weight': 5, 'gamma': 3.1624301885368222, 'grow_policy': 'lossguide'}. Best is trial 7 with value: 27833.452553678064.\n",
            "[I 2025-02-16 15:09:55,548] Trial 13 finished with value: 28001.90188871356 and parameters: {'booster': 'dart', 'lambda': 0.0015441536658403964, 'alpha': 0.015133524934104782, 'colsample_bytree': 0.3955701796110753, 'subsample': 0.7784498949934768, 'learning_rate': 0.03953491434459362, 'n_estimators': 121, 'max_depth': 5, 'min_child_weight': 3, 'gamma': 1.9584941935440343, 'grow_policy': 'lossguide'}. Best is trial 7 with value: 27833.452553678064.\n",
            "[I 2025-02-16 15:10:48,292] Trial 14 finished with value: 28545.461199970483 and parameters: {'booster': 'dart', 'lambda': 0.002362302844049805, 'alpha': 0.008739618045568259, 'colsample_bytree': 0.38849917912728993, 'subsample': 0.7972708347273909, 'learning_rate': 0.035129987346339854, 'n_estimators': 134, 'max_depth': 5, 'min_child_weight': 1, 'gamma': 2.0994238473096662, 'grow_policy': 'lossguide'}. Best is trial 7 with value: 27833.452553678064.\n",
            "[I 2025-02-16 15:11:28,013] Trial 15 finished with value: 32854.85807039289 and parameters: {'booster': 'dart', 'lambda': 0.0011231751664928598, 'alpha': 0.024398569315701075, 'colsample_bytree': 0.392472833708875, 'subsample': 0.7383760791689794, 'learning_rate': 0.02646961373873995, 'n_estimators': 116, 'max_depth': 4, 'min_child_weight': 7, 'gamma': 1.7962057556220241, 'grow_policy': 'lossguide'}. Best is trial 7 with value: 27833.452553678064.\n",
            "[I 2025-02-16 15:13:35,556] Trial 16 finished with value: 28494.097401648483 and parameters: {'booster': 'dart', 'lambda': 0.07679933184746392, 'alpha': 0.018153982278321337, 'colsample_bytree': 0.41737879649176785, 'subsample': 0.7448688784750154, 'learning_rate': 0.0324107754050928, 'n_estimators': 537, 'max_depth': 5, 'min_child_weight': 7, 'gamma': 3.76019779899825, 'grow_policy': 'lossguide'}. Best is trial 7 with value: 27833.452553678064.\n",
            "[I 2025-02-16 15:14:17,503] Trial 17 finished with value: 27659.874760381623 and parameters: {'booster': 'dart', 'lambda': 0.04611265475836672, 'alpha': 0.026516888430749817, 'colsample_bytree': 0.6594143291754357, 'subsample': 0.615598606600005, 'learning_rate': 0.0672438656834272, 'n_estimators': 818, 'max_depth': 8, 'min_child_weight': 2, 'gamma': 0.018307079310446728, 'grow_policy': 'lossguide'}. Best is trial 17 with value: 27659.874760381623.\n",
            "[I 2025-02-16 15:21:59,127] Trial 18 finished with value: 29769.93987776846 and parameters: {'booster': 'dart', 'lambda': 0.1880924107061286, 'alpha': 0.04498960427392113, 'colsample_bytree': 0.6501500401633878, 'subsample': 0.6029915016436684, 'learning_rate': 0.013703099372629337, 'n_estimators': 821, 'max_depth': 8, 'min_child_weight': 7, 'gamma': 0.0891078270186201, 'grow_policy': 'depthwise'}. Best is trial 17 with value: 27659.874760381623.\n",
            "[I 2025-02-16 15:22:20,152] Trial 19 finished with value: 28330.067190781432 and parameters: {'booster': 'dart', 'lambda': 0.03628385200826191, 'alpha': 1.8331621517750671, 'colsample_bytree': 0.639855887226028, 'subsample': 0.6176137170280088, 'learning_rate': 0.07800187080728575, 'n_estimators': 932, 'max_depth': 7, 'min_child_weight': 2, 'gamma': 0.029020368474488495, 'grow_policy': 'lossguide'}. Best is trial 17 with value: 27659.874760381623.\n",
            "[I 2025-02-16 15:37:20,157] Trial 20 finished with value: 30094.74661308538 and parameters: {'booster': 'dart', 'lambda': 1.8679823306414969, 'alpha': 0.002363016348792545, 'colsample_bytree': 0.7992073806821318, 'subsample': 0.625005138245083, 'learning_rate': 0.011608341327790136, 'n_estimators': 637, 'max_depth': 7, 'min_child_weight': 9, 'gamma': 3.77664310891024, 'grow_policy': 'lossguide'}. Best is trial 17 with value: 27659.874760381623.\n",
            "[I 2025-02-16 15:38:30,668] Trial 21 finished with value: 27515.745341158945 and parameters: {'booster': 'dart', 'lambda': 0.003328321078594364, 'alpha': 0.014066987907664646, 'colsample_bytree': 0.6066421844014087, 'subsample': 0.7199701447574686, 'learning_rate': 0.09117464916543548, 'n_estimators': 798, 'max_depth': 4, 'min_child_weight': 3, 'gamma': 2.6526414977135673, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 27515.745341158945.\n",
            "[I 2025-02-16 15:39:17,548] Trial 22 finished with value: 27881.826343451536 and parameters: {'booster': 'dart', 'lambda': 0.0039662845585865854, 'alpha': 0.03345233665891969, 'colsample_bytree': 0.6100253560607365, 'subsample': 0.7141436552915562, 'learning_rate': 0.11001574379247327, 'n_estimators': 773, 'max_depth': 4, 'min_child_weight': 3, 'gamma': 2.7393401754067086, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 27515.745341158945.\n",
            "[I 2025-02-16 15:39:44,758] Trial 23 finished with value: 28976.75716479227 and parameters: {'booster': 'dart', 'lambda': 0.03444192309847818, 'alpha': 0.008874376149635288, 'colsample_bytree': 0.7128276286172606, 'subsample': 0.6394947776823737, 'learning_rate': 0.07892779890679408, 'n_estimators': 820, 'max_depth': 4, 'min_child_weight': 6, 'gamma': 3.3274314238852156, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 27515.745341158945.\n",
            "[I 2025-02-16 15:41:24,531] Trial 24 finished with value: 27095.75341263808 and parameters: {'booster': 'dart', 'lambda': 1.5649409493871511, 'alpha': 0.0749062834862232, 'colsample_bytree': 0.6020628737060525, 'subsample': 0.7119633202256755, 'learning_rate': 0.07378966495062211, 'n_estimators': 998, 'max_depth': 3, 'min_child_weight': 1, 'gamma': 1.4564349529477008, 'grow_policy': 'lossguide'}. Best is trial 24 with value: 27095.75341263808.\n"
          ]
        }
      ],
      "source": [
        "# Create and run an Optuna study\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=50)  # Increased number of trials\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siK_FtlIaiqq"
      },
      "outputs": [],
      "source": [
        "# Pre-trained models with hyperparameters\n",
        "xgb_tunned = XGBRegressor(n_estimators=6500, alpha=1.7938525031017074e-09, subsample=0.3231512729662032,\n",
        "                          colsample_bytree=0.25528017285233484, max_depth=5, min_child_weight=2,\n",
        "                          learning_rate=0.004828231865923587, gamma=0.0026151163125498213, random_state=1)\n",
        "\n",
        "gbm_tunned = GradientBoostingRegressor(n_estimators=5500, max_depth=5, min_samples_leaf=14,\n",
        "                                       learning_rate=0.006328507206504974, subsample=0.9170443266552768,\n",
        "                                       max_features='sqrt', random_state=1)\n",
        "\n",
        "lgbm_tunned = LGBMRegressor(n_estimators=7000, max_depth=7, learning_rate=0.002536841439596437,\n",
        "                            min_data_in_leaf=22, subsample=0.7207500503954922, max_bin=210,\n",
        "                            feature_fraction=0.30010067215105635, random_state=1, verbosity=-1)\n",
        "\n",
        "catboost_tunned = CatBoostRegressor(iterations=4500, colsample_bylevel=0.05367479984702603,\n",
        "                                    learning_rate=0.018477566955501026, random_strength=0.1321272840705348,\n",
        "                                    depth=6, l2_leaf_reg=4, boosting_type='Plain', bootstrap_type='Bernoulli',\n",
        "                                    subsample=0.7629052520889268, logging_level='Silent', random_state=1)\n",
        "\n",
        "elasticnet_tunned = ElasticNet(max_iter=3993, alpha=0.0007824887724782356, l1_ratio=0.25,\n",
        "                               tol=3.78681184748232e-06, random_state=1)\n",
        "\n",
        "lasso_tunned = Lasso(max_iter=2345, alpha=0.00019885959230548468, tol=2.955506894549702e-05, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbavGy8abLD0"
      },
      "outputs": [],
      "source": [
        "# Create pipelines for each model\n",
        "pipe_xgb = Pipeline(steps=[\n",
        "    ('tree_preprocessor', tree_preprocessor),\n",
        "    ('regressor1', xgb_tunned),\n",
        "])\n",
        "\n",
        "pipe_gbm = Pipeline(steps=[\n",
        "    ('tree_preprocessor', tree_preprocessor),\n",
        "    ('regressor2', gbm_tunned),\n",
        "])\n",
        "\n",
        "pipe_lgbm = Pipeline(steps=[\n",
        "    ('tree_preprocessor', tree_preprocessor),\n",
        "    ('regressor3', lgbm_tunned),\n",
        "])\n",
        "\n",
        "pipe_catboost = Pipeline(steps=[\n",
        "    ('tree_preprocessor', tree_preprocessor),\n",
        "    ('regressor4', catboost_tunned),\n",
        "])\n",
        "\n",
        "pipe_Elasticnet = Pipeline(steps=[\n",
        "    ('linear_preprocessor', linear_preprocessor),\n",
        "    ('regressor5', elasticnet_tunned),\n",
        "])\n",
        "\n",
        "TargetTransformedElasticnet = TransformedTargetRegressor(regressor=pipe_Elasticnet, func=np.log1p, inverse_func=np.expm1)\n",
        "\n",
        "pipe_Lasso = Pipeline(steps=[\n",
        "    ('linear_preprocessor', linear_preprocessor),\n",
        "    ('regressor6', lasso_tunned),\n",
        "])\n",
        "\n",
        "TargetTransformedLasso = TransformedTargetRegressor(regressor=pipe_Lasso, func=np.log1p, inverse_func=np.expm1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hksnSNXfbPR1"
      },
      "outputs": [],
      "source": [
        "# Define the stacking regressor\n",
        "estimators = [\n",
        "    ('xgb', pipe_xgb),\n",
        "    ('gbm', pipe_gbm),\n",
        "    ('lgbm', pipe_lgbm),\n",
        "    ('catboost', pipe_catboost),\n",
        "    ('elasticnet', TargetTransformedElasticnet),\n",
        "    ('lasso', TargetTransformedLasso),\n",
        "]\n",
        "\n",
        "stacking_regressor = StackingRegressor(\n",
        "    estimators=estimators,\n",
        "    final_estimator=LinearRegression()\n",
        ")\n",
        "\n",
        "# Fit the stacking regressor\n",
        "stacking_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "predictions = stacking_regressor.predict(X_test_processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wJDNMKRdBnv"
      },
      "outputs": [],
      "source": [
        "# Model Training and Prediction\n",
        "final_model = xgb.XGBRegressor(**best_params)\n",
        "final_model.fit(X_train_processed, y_train)\n",
        "\n",
        "predictions = final_model.predict(X_test_processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yd_L3NykzIOr"
      },
      "outputs": [],
      "source": [
        "# Evaluate accuracy on validation set\n",
        "val_predictions = final_model.predict(X_val_processed)\n",
        "\n",
        "# Calculate RMSE without 'squared' argument and take the square root manually\n",
        "rmse = mean_squared_error(y_val, val_predictions)**0.5\n",
        "\n",
        "print(f\"Validation RMSE: {rmse}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdRFTdmCd4ws"
      },
      "outputs": [],
      "source": [
        "#submission_df = pd.DataFrame({'Id': test_df['Id'], 'SalePrice': predictions})\n",
        "#submission_df.to_csv('submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4dHEG6qDVlH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1oV2A2mi6TWoYsuzup3a2LqP8WJVijwiU",
      "authorship_tag": "ABX9TyOIJ/fdJHtRAuBk3KHmZE/p"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}