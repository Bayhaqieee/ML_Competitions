{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-13T04:43:18.724488Z","iopub.execute_input":"2025-02-13T04:43:18.724706Z","iopub.status.idle":"2025-02-13T04:43:19.044516Z","shell.execute_reply.started":"2025-02-13T04:43:18.724680Z","shell.execute_reply":"2025-02-13T04:43:19.043657Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## The main method here is the voting ensemble of xgboost and catboost classifiers\n- ### In this version, the sklearn pipeline parameters which i used for the method will be shown.\n- ### This notebook aims to provide a quick solution, therefore the EDA and actual tuning part is omitted.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntrain_y = df['Survived']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T04:43:19.045537Z","iopub.execute_input":"2025-02-13T04:43:19.045950Z","iopub.status.idle":"2025-02-13T04:43:19.066985Z","shell.execute_reply.started":"2025-02-13T04:43:19.045922Z","shell.execute_reply":"2025-02-13T04:43:19.066096Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T04:43:19.067887Z","iopub.execute_input":"2025-02-13T04:43:19.068217Z","iopub.status.idle":"2025-02-13T04:43:19.099678Z","shell.execute_reply.started":"2025-02-13T04:43:19.068187Z","shell.execute_reply":"2025-02-13T04:43:19.098547Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 418 entries, 0 to 417\nData columns (total 11 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  418 non-null    int64  \n 1   Pclass       418 non-null    int64  \n 2   Name         418 non-null    object \n 3   Sex          418 non-null    object \n 4   Age          332 non-null    float64\n 5   SibSp        418 non-null    int64  \n 6   Parch        418 non-null    int64  \n 7   Ticket       418 non-null    object \n 8   Fare         417 non-null    float64\n 9   Cabin        91 non-null     object \n 10  Embarked     418 non-null    object \ndtypes: float64(2), int64(4), object(5)\nmemory usage: 36.0+ KB\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"test_id = test_df['PassengerId']\ntest_df = test_df.drop(columns=['PassengerId', 'Name'])\ndf = df.drop(columns=['PassengerId', 'Name'])\ntest_numeric_cols = test_df.select_dtypes(include=[np.number]).columns\ntest_categorical_cols = test_df.select_dtypes(include=['object']).columns\ntest_df[test_numeric_cols] = test_df[test_numeric_cols].fillna(-1)\ntest_df[test_categorical_cols] = test_df[test_categorical_cols].fillna('No Attribute')\n\nnumeric_cols = df.select_dtypes(include=[np.number]).columns\ncategorical_cols = df.select_dtypes(include=['object']).columns\ndf[numeric_cols] = df[numeric_cols].fillna(-1)\ndf[categorical_cols] = df[categorical_cols].fillna('No Attribute')\ndf.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T04:43:19.101006Z","iopub.execute_input":"2025-02-13T04:43:19.101394Z","iopub.status.idle":"2025-02-13T04:43:19.123919Z","shell.execute_reply.started":"2025-02-13T04:43:19.101363Z","shell.execute_reply":"2025-02-13T04:43:19.123004Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 10 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   Survived  891 non-null    int64  \n 1   Pclass    891 non-null    int64  \n 2   Sex       891 non-null    object \n 3   Age       891 non-null    float64\n 4   SibSp     891 non-null    int64  \n 5   Parch     891 non-null    int64  \n 6   Ticket    891 non-null    object \n 7   Fare      891 non-null    float64\n 8   Cabin     891 non-null    object \n 9   Embarked  891 non-null    object \ndtypes: float64(2), int64(4), object(4)\nmemory usage: 69.7+ KB\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"numeric_cols = numeric_cols.drop('Survived')\n\nseed = 42\ndf = df.drop(columns=['Survived'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T04:43:19.124901Z","iopub.execute_input":"2025-02-13T04:43:19.125149Z","iopub.status.idle":"2025-02-13T04:43:19.142172Z","shell.execute_reply.started":"2025-02-13T04:43:19.125127Z","shell.execute_reply":"2025-02-13T04:43:19.141175Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Pipeline","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom category_encoders import CatBoostEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom xgboost import XGBClassifier\nimport optuna\n\n\n\nnumeric_transformer = Pipeline(steps=[\n    ('scaler', StandardScaler())\n])\ncategorical_transformer = Pipeline(steps=[\n    ('catboost', CatBoostEncoder(cols=categorical_cols, random_state=seed))\n])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ]\n)\nX_train, X_val, y_train, y_val = train_test_split(df, train_y, test_size=0.2, random_state=seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T04:43:19.143984Z","iopub.execute_input":"2025-02-13T04:43:19.144232Z","iopub.status.idle":"2025-02-13T04:43:22.558557Z","shell.execute_reply.started":"2025-02-13T04:43:19.144212Z","shell.execute_reply":"2025-02-13T04:43:22.557310Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Objective Function","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ndef objective(trial):\n    xgb_param = {\n        \"learning_rate\": trial.suggest_float(\"classifier__xgb__learning_rate\", 1e-4, 1e-1, log=True),\n        \"max_depth\": trial.suggest_int(\"classifier__xgb__max_depth\", 2, 10),\n        \"subsample\": trial.suggest_float(\"classifier__xgb__subsample\", 0.5, 1.0),\n        \"colsample_bytree\": trial.suggest_float(\"classifier__xgb__colsample_bytree\", 0.5, 1.0),\n        \"n_estimators\": trial.suggest_int(\"classifier__xgb__n_estimators\", 50, 300),\n    }\n    cat_param = {\n        \"learning_rate\": trial.suggest_float(\"classifier__cat__learning_rate\", 1e-4, 1e-1, log=True),\n        \"depth\": trial.suggest_int(\"classifier__cat__depth\", 2, 10),\n        \"iterations\": trial.suggest_int(\"classifier__cat__iterations\", 50, 300),\n        \"l2_leaf_reg\": trial.suggest_float(\"classifier__cat__l2_leaf_reg\", 1e-8, 100.0, log=True),\n        \"subsample\": trial.suggest_float(\"classifier__cat__subsample\", 0.5, 1.0),\n        \"random_strength\": trial.suggest_float(\"classifier__cat__random_strength\", 1e-8, 100.0, log=True)\n    }\n    clf1 =  XGBClassifier(random_state = seed, **xgb_param)\n    clf2 = CatBoostClassifier(random_state=seed, **cat_param, verbose=0)\n    voting_param = {\n        'voting': trial.suggest_categorical('classifier__voting', ['hard', 'soft']),\n    }\n\n    voting_clf = VotingClassifier(\n        estimators= [\n            ('xgb', clf1),\n            ('cat', clf2),\n        ],\n        **voting_param\n    )\n    voting_pipeline = Pipeline(\n    steps=[\n        ('preprocessor', preprocessor),\n        ('classifier', voting_clf)\n    ]\n    )\n    voting_pipeline.fit(X_train, y_train)\n    score = accuracy_score(voting_pipeline.predict(X_val), y_val)\n    return score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T04:43:22.560141Z","iopub.execute_input":"2025-02-13T04:43:22.560695Z","iopub.status.idle":"2025-02-13T04:43:22.568023Z","shell.execute_reply.started":"2025-02-13T04:43:22.560658Z","shell.execute_reply":"2025-02-13T04:43:22.566996Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Best Param","metadata":{}},{"cell_type":"code","source":"best_params = {'classifier__xgb__learning_rate': 0.009733169933147993,\n  'classifier__xgb__max_depth': 10,\n  'classifier__xgb__subsample': 0.9916455907992193,\n  'classifier__xgb__colsample_bytree': 0.8675483544879838,\n  'classifier__xgb__n_estimators': 164,\n  'classifier__cat__learning_rate': 0.0001201004987557868,\n  'classifier__cat__depth': 7,\n  'classifier__cat__iterations': 268,\n  'classifier__cat__l2_leaf_reg': 0.001122571062590311,\n  'classifier__cat__subsample': 0.8131673802913759,\n  'classifier__cat__random_strength': 0.009637223973016262,\n  'classifier__voting': 'hard'}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T04:43:22.569431Z","iopub.execute_input":"2025-02-13T04:43:22.569749Z","iopub.status.idle":"2025-02-13T04:43:22.625816Z","shell.execute_reply.started":"2025-02-13T04:43:22.569717Z","shell.execute_reply":"2025-02-13T04:43:22.624883Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Result Generation","metadata":{}},{"cell_type":"code","source":"clf1 =  XGBClassifier(random_state = seed)\nclf2 = CatBoostClassifier(random_state=seed, verbose=0)\n\nvoting_clf = VotingClassifier(\n    estimators= [\n            ('xgb', clf1),\n            ('cat', clf2),\n        ],\n)\nvoting_pipeline = Pipeline(\nsteps=[\n    ('preprocessor', preprocessor),\n    ('classifier', voting_clf)\n]\n)\nvoting_pipeline.set_params(**best_params)\nvoting_pipeline.fit(X_train, y_train)\nresult_df = pd.DataFrame()\nresult_df['PassengerId'] = test_id\nresult_df['Survived'] = voting_pipeline.predict(test_df)\n\nresult_df.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T04:43:22.626609Z","iopub.execute_input":"2025-02-13T04:43:22.626926Z","iopub.status.idle":"2025-02-13T04:43:23.505219Z","shell.execute_reply.started":"2025-02-13T04:43:22.626901Z","shell.execute_reply":"2025-02-13T04:43:23.503444Z"}},"outputs":[],"execution_count":9}]}